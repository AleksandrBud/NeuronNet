{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HW_8.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNMAEhF9WsbNALRA1qUMk2S"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"s6R0z-ifK4FI","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XsaB3j7chUmJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":156},"executionInfo":{"status":"ok","timestamp":1595656211519,"user_tz":-300,"elapsed":2621,"user":{"displayName":"Александр Будзин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQDO_1iot49opUo9xhp4nB1NuDnu7f_m8JITnvwg=s64","userId":"09074016947260546405"}},"outputId":"f1bf87bc-1717-4c10-b539-b1851f508a26"},"source":["batch_size = 64\n","(x_train, _), (x_test, _) = keras.datasets.fashion_mnist.load_data()  #.mnist.load_data()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","32768/29515 [=================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","26427392/26421880 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","8192/5148 [===============================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","4423680/4422102 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4rqTpz6phXZw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595657194406,"user_tz":-300,"elapsed":962,"user":{"displayName":"Александр Будзин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQDO_1iot49opUo9xhp4nB1NuDnu7f_m8JITnvwg=s64","userId":"09074016947260546405"}},"outputId":"2e8762a4-dfb7-4e66-84e9-2ea1c53b30d4"},"source":["x_train.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(60000, 28, 28)"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"ZzxXHzCYObN5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":156},"executionInfo":{"status":"ok","timestamp":1595651639272,"user_tz":-300,"elapsed":2299,"user":{"displayName":"Александр Будзин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQDO_1iot49opUo9xhp4nB1NuDnu7f_m8JITnvwg=s64","userId":"09074016947260546405"}},"outputId":"17315cb3-39a1-4e4d-8aa5-d304dd63af01"},"source":["\n","all_digits = np.concatenate([x_train, x_test])\n","all_digits = all_digits.astype(\"float32\") / 255\n","all_digits = np.reshape(all_digits, (-1, 28, 28, 1))\n","dataset = tf.data.Dataset.from_tensor_slices(all_digits)\n","dataset = dataset.shuffle(buffer_size=1024).batch(batch_size).prefetch(32)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","32768/29515 [=================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","26427392/26421880 [==============================] - 1s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","8192/5148 [===============================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","4423680/4422102 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pVJBpqc0ObLO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":364},"executionInfo":{"status":"ok","timestamp":1595651641604,"user_tz":-300,"elapsed":946,"user":{"displayName":"Александр Будзин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQDO_1iot49opUo9xhp4nB1NuDnu7f_m8JITnvwg=s64","userId":"09074016947260546405"}},"outputId":"435faed6-9bff-4628-9c09-cb5f3ccbb0d6"},"source":["discriminator = keras.Sequential(\n","    [\n","        keras.Input(shape=(28, 28, 1)),\n","        layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n","        layers.LeakyReLU(alpha=0.2),\n","        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n","        layers.LeakyReLU(alpha=0.2),\n","        layers.GlobalMaxPooling2D(),\n","        layers.Dense(1),\n","    ],\n","    name=\"discriminator\",\n",")\n","\n","discriminator.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"discriminator\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_3 (Conv2D)            (None, 14, 14, 64)        640       \n","_________________________________________________________________\n","leaky_re_lu_5 (LeakyReLU)    (None, 14, 14, 64)        0         \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 7, 7, 128)         73856     \n","_________________________________________________________________\n","leaky_re_lu_6 (LeakyReLU)    (None, 7, 7, 128)         0         \n","_________________________________________________________________\n","global_max_pooling2d_1 (Glob (None, 128)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 1)                 129       \n","=================================================================\n","Total params: 74,625\n","Trainable params: 74,625\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5CUr5MwtObI7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":434},"executionInfo":{"status":"ok","timestamp":1595651644207,"user_tz":-300,"elapsed":859,"user":{"displayName":"Александр Будзин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQDO_1iot49opUo9xhp4nB1NuDnu7f_m8JITnvwg=s64","userId":"09074016947260546405"}},"outputId":"9213d431-1287-4516-b3fa-e9c1c89b646e"},"source":["latent_dim = 128\n","\n","generator = keras.Sequential(\n","    [\n","        keras.Input(shape=(latent_dim,)),\n","        # строим размер входного вектора 7x7x128 map\n","        layers.Dense(7 * 7 * 128),\n","        layers.LeakyReLU(alpha=0.2),\n","        layers.Reshape((7, 7, 128)),\n","        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n","        layers.LeakyReLU(alpha=0.2),\n","        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n","        layers.LeakyReLU(alpha=0.2),\n","        layers.Conv2D(1, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n","    ],\n","    name=\"generator\",\n",")\n","\n","generator.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"generator\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_3 (Dense)              (None, 6272)              809088    \n","_________________________________________________________________\n","leaky_re_lu_7 (LeakyReLU)    (None, 6272)              0         \n","_________________________________________________________________\n","reshape_1 (Reshape)          (None, 7, 7, 128)         0         \n","_________________________________________________________________\n","conv2d_transpose_2 (Conv2DTr (None, 14, 14, 128)       262272    \n","_________________________________________________________________\n","leaky_re_lu_8 (LeakyReLU)    (None, 14, 14, 128)       0         \n","_________________________________________________________________\n","conv2d_transpose_3 (Conv2DTr (None, 28, 28, 128)       262272    \n","_________________________________________________________________\n","leaky_re_lu_9 (LeakyReLU)    (None, 28, 28, 128)       0         \n","_________________________________________________________________\n","conv2d_5 (Conv2D)            (None, 28, 28, 1)         6273      \n","=================================================================\n","Total params: 1,339,905\n","Trainable params: 1,339,905\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jiNqOnwUObG8","colab_type":"code","colab":{}},"source":["class GAN(keras.Model):\n","    def __init__(self, discriminator, generator, latent_dim):\n","        super(GAN, self).__init__()\n","        self.discriminator = discriminator\n","        self.generator = generator\n","        self.latent_dim = latent_dim\n","\n","    def compile(self, d_optimizer, g_optimizer, loss_fn):\n","        super(GAN, self).compile()\n","        self.d_optimizer = d_optimizer\n","        self.g_optimizer = g_optimizer\n","        self.loss_fn = loss_fn\n","\n","    def train_step(self, real_images):\n","        if isinstance(real_images, tuple):\n","            real_images = real_images[0]\n","        # берем случайный пример из скрытого пространства\n","        batch_size = tf.shape(real_images)[0]\n","        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n","\n","        # Строим по нему фейковое изображение\n","        generated_images = self.generator(random_latent_vectors)\n","\n","        # собрали с реальным в тензор\n","        combined_images = tf.concat([generated_images, real_images], axis=0)\n","\n","        # задаем метки 1 и 0 соответственно\n","        labels = tf.concat(\n","            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n","        )\n","        # Добавляем шум !!!\n","        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n","\n","        # учим discriminator\n","        with tf.GradientTape() as tape:\n","            predictions = self.discriminator(combined_images)\n","            d_loss = self.loss_fn(labels, predictions)\n","        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n","        self.d_optimizer.apply_gradients(\n","            zip(grads, self.discriminator.trainable_weights)\n","        )\n","\n","        #Выбрали случайный пример в скрытом пространстве\n","        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n","\n","        # собрали метки реальных изображений\n","        misleading_labels = tf.zeros((batch_size, 1))\n","\n","        # Учим generator !\n","        with tf.GradientTape() as tape:\n","            predictions = self.discriminator(self.generator(random_latent_vectors))\n","            g_loss = self.loss_fn(misleading_labels, predictions)\n","        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n","        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n","        return {\"d_loss\": d_loss, \"g_loss\": g_loss}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ua55AsnSObEv","colab_type":"code","colab":{}},"source":["class GANMonitor(keras.callbacks.Callback):\n","    def __init__(self, num_img=3, latent_dim=128):\n","        self.num_img = num_img\n","        self.latent_dim = latent_dim\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n","        generated_images = self.model.generator(random_latent_vectors)\n","        generated_images *= 255\n","        generated_images.numpy()\n","        for i in range(self.num_img):\n","            img = keras.preprocessing.image.array_to_img(generated_images[i])\n","            img.save(\"generated_img_{i}_{epoch}.png\".format(i=i, epoch=epoch))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F3PN4t-DObCa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":139},"executionInfo":{"status":"ok","timestamp":1595651825749,"user_tz":-300,"elapsed":174710,"user":{"displayName":"Александр Будзин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQDO_1iot49opUo9xhp4nB1NuDnu7f_m8JITnvwg=s64","userId":"09074016947260546405"}},"outputId":"b4502dc2-ee9f-4684-9004-8b86b89a6645"},"source":["epochs = 3\n","\n","gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n","gan.compile(\n","    d_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n","    g_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n","    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n",")\n","\n","gan.fit(\n","    dataset, epochs=epochs, callbacks=[GANMonitor(num_img=3, latent_dim=latent_dim)]\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/3\n","1094/1094 [==============================] - 57s 52ms/step - d_loss: 0.4605 - g_loss: 1.4556\n","Epoch 2/3\n","1094/1094 [==============================] - 57s 52ms/step - d_loss: 0.5934 - g_loss: 1.2040\n","Epoch 3/3\n","1094/1094 [==============================] - 57s 52ms/step - d_loss: 0.6519 - g_loss: 0.9466\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f9733bd3be0>"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"xpjofq5mObAA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":101},"executionInfo":{"status":"ok","timestamp":1595651832926,"user_tz":-300,"elapsed":1141,"user":{"displayName":"Александр Будзин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQDO_1iot49opUo9xhp4nB1NuDnu7f_m8JITnvwg=s64","userId":"09074016947260546405"}},"outputId":"0306ba27-ccc0-4bff-b118-479a582133c5"},"source":["from IPython.display import Image, display\n","\n","display(Image(\"generated_img_0_2.png\"))\n","display(Image(\"generated_img_1_2.png\"))\n","display(Image(\"generated_img_2_2.png\"))"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAB6ElEQVR4nJWRP2tTYRTGz3n/NOnNNalJap0C7aJDsSkILuKgS8HFVZz8ALrpl3DwAzgI4qBCB0FQEUQcohBUcFBLRUQNzY0mzW1u7k3u+573OMSGxNTBMx3Oj+ecw/MA/F/huBN/EQHr/5adW7m/dDDxWw+Nde8Pzx0E9etju5+HV0sgZ2/6ZsfvXA9fxkCzwtqT+Nr2m+a9NZzZm8mRpc2ol/bvFgqjkRrDobaOzzjLuh4J5OmbR6uiSciJS31wPP0QPjiUloVNJSlAMfntOmzb0yf0nDQatSrvC0bQwFJoLoKAImqGT5zbhwgAdzRdMcwWUElFG4XzI/NF/pJX/1C9kbuVWXQIjoCQ1055CAIAvqQROf5OxmzF/Xgv7ic2qAUXdGHBQ4FDYckWyVFFzskMSsGDtvVKg4pT4vK79l5kUmQpJAhUUkL+13wwcGkV1Yuz0qnS6s2KJS2ck8jc7LwCI7rfjAA7NMmPp89D13GWB2ysMWHaSDEw/Mdb9gWXpbBZ1k7bIF5wBszY+NsrFV8wkZJMYU1s0WQqH02CLMN+3ovV29azaCqyk/P5ONexPdfAZUzbykym0q1/xR5FR7KLUhezy95UZBubg53dNsU/4wSPl/x4au3j1ZbRlFDXmf6jRjAEAIDfwbPurk3kouwAAAAASUVORK5CYII=\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABy0lEQVR4nK3Ru2tTcRQH8O/vce81pSTNjTQlUiUQqBUddXMSOqnoIC6d6yYURwf9A6SLg6uLqy8crIMgiiCYgkPUKNTSPGlSmya9z9+9v+PQpsV7cfM3Hc6H8+D8gP/3DHYY8qSxpdl/VBVWejH9mkmDBYb7062P4fVjaZyByd8vvM3Xp1kaX069+uCvrr/oLGdSVuw3fRW1BrXOu9K49HBbr25GKpz0Np35AvG/cbZSRrwdeL1mRCdB+0l5gIvzJicrHG19Mudq426SETC19PQeEz5zkfPXi/EOCGBGyCSyw6uVO6HUmoeIs5mR2FVgxIggpLjceHTLvs20UEwbzmq9+F1BaIKyTLl483fhmciTgEETIJv3whiaCCyI5PJc2wT8LBFXWlpVb8NiPOMABM2ftHKKYpvAODeMoB9IobUDACCwayu1xuae1joK+t5aGVeSd2dnhioM3J3tjQXj4tEX70f09fNgzx0N/BOl45eSCGYLi/tuhsvO4yiJ9HDwo7rV97wvaB9NG9/29RoPSxcm7fPViTCF3TbJ5jlulE/dyN1NtIUk8Gy+u/u8cfpBciYUgwx+dt+URNFJtdWAq+rs7LD8rVKPD5J/AGSox2jgolwmAAAAAElFTkSuQmCC\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABuElEQVR4nG2Sv09UQRDHZ2b3vcfzvQdYkBON0cRCIcTCxISERrozVEL8PzSW/gF2tiZ2tBZW0kplYowCiVfBeRdRhHCBkzvuB/t2Zywed3EPptv95Dvf7+wsgFc6Ulk0PJHH8GE5WHji3w3r+cdqulkOLkPqUf139U39fXwZ7AnnlvnvixJe9Fzf6n4+2TffNw7VRfhzZX+n/6q3RiLn+f6DlVK6e9Wku2uvoTHieDMy1jX6HdOqvSwXGj2EezNnJKoPLmhuVHXue84syFGei4E8rrTciPLZsUyisHLqT9wvEunQFME+PP4UIgC5QKZOOwWkgkFYyW+DCDFa+sUxeXOaVRuhKFBO8zWTjjzCU4pAA0EgUKe2eIHC5cApQEZRkBgrnjI1HAgKAQg1bIQenD9AJCAkUBzn2m+7NefyEIFBHFSh6QdayajNlh1YJsvsw6azGWhUrEl1z9kQfnvX7hkRC0g2HOxz4Fkfb46ZM3M4fmUs/oIjMK7dnWj82E5v3biXLa1b57Wd7HVDSpLZ63cCaNnE98y+nrS2p46SU2C7ONjG4A9F2f0He7XjidLs9OLqW+wAAMA/XfO/Aw17WcoAAAAASUVORK5CYII=\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"fj3P_8QMOa84","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":101},"executionInfo":{"status":"ok","timestamp":1595651837352,"user_tz":-300,"elapsed":878,"user":{"displayName":"Александр Будзин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQDO_1iot49opUo9xhp4nB1NuDnu7f_m8JITnvwg=s64","userId":"09074016947260546405"}},"outputId":"a51c5d6e-f155-4325-c994-1fcb65e70164"},"source":["display(Image(\"generated_img_0_0.png\"))\n","display(Image(\"generated_img_0_1.png\"))\n","display(Image(\"generated_img_0_2.png\"))"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABSUlEQVR4nHWSvUoDQRSFv9lN/ItgIRJQENFCxVKwFBsRCx/Axsoib2BlqViktxRsfBLBXgsFUbCQIIKCBDFkz7HYze4mmgMDM/Nx5p65M+ioKoNNT5GtdSkQEOBspFq0pboAFCENOj2tXYAECIByGMurrXSqZZyAC/hj+zNdCqgA4zm0payIhVXOg23btOaIiAhOy+ZU5p6LB/ALdjkPdsdWJdlKz7uDPqNORQzgKyQ4yJlsW2r30paV4EsDHwCqlLkkyxZS+OOUnHjFwBOAlngE3ouCqTOC8gU9AvP5K82UzjtE1rZkCbuDojhnNaj69flE8lm3yLG31ohBb3S9QTOvmQCwGb6yzN8ARHRvcufCZLcJmoXsgWtVJQkNANoIGOVf6fx6oIPhVp2p/fR2HO8M9rdw1tFwSNbHIXBkcG8i9H2bfo0RB4Bf4+PNnkrSOPsAAAAASUVORK5CYII=\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACsUlEQVR4nF3R309SYRgH8Oc9vBwGBxRFOCAqgmSJk9AUdblos7acbdq6cbV14bqrm/Kiu+qqzTVbW+svaHXjhenm1uaWlqWSaKaICRKIAYVw5KcgP87pAnTN5/L97Pt9nu1FcDKN1XsUL8kQh6njF3RifEf4Yw8LlcrK8YG0DCEOACOuhG01Kkz7qjAFHYJCFDgAwMcGtgRv2rKswdz2q2HDGwAAwCe1BYLfyKlqsFAjyzxZP7WTfss9vvmhbsEyE06TqVNJzfNn/R22G+rr7vvkxcsxxP2Pq1L398qg0y7eMn9xpkjIcceIibzkqcl2ptYY790fudJzy7iqvzNHFFFVJR2hDvIxGXP007E99u2ufXSJVpfQn+Glx0MyqbK8nkpKGhN7mmFzS2+plte9MXsYCkRIr3snapuKpa0vHlpxCRf1DyrSpBDCbEpkNg12/biE2xxHpdrJNZc+FIkGsZ30rq3Prjgdo0uL4WISjQnkdIDOtdt8W/v+eWmSo+419eFikiNa/euxQo7Q6trE0lw2LbG+3uU7SjsDInsnq0blXmY1EN3N0/W686LUH4yAA+BF4X3dtG467yKMqg09/xqTZaKsiyA4AChc2OgnE+rbXSpVNhv/FaGy4ququgPMAgBA4mhiPxacp9xyKidEvrn8lJfaDBHFz+7qeGmpUlo0ZHlULoBcRatMvrKQLl7Ls808Wg7uvbN+9icoVBDC7zXJ2WooIkpODuXKtENNynZts9Ik6qSN3ewOSyAAAE7Y8pVROybcKIoJBRgi1R4WhwETBQAgvWFxME6ZDYP6eI1eFqEbyLJFBnD75iHLGxCgVWa7wVfr5LlkYQ92Cj8ZaRKwJwlQmEFI6y/LGBRSnUCxiwTnoE8ylQeE8wCATNJQFvMFzTGFh7ZzqP5vkJ9iMv8AjXMc3hPRi1kAAAAASUVORK5CYII=\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAB6ElEQVR4nJWRP2tTYRTGz3n/NOnNNalJap0C7aJDsSkILuKgS8HFVZz8ALrpl3DwAzgI4qBCB0FQEUQcohBUcFBLRUQNzY0mzW1u7k3u+573OMSGxNTBMx3Oj+ecw/MA/F/huBN/EQHr/5adW7m/dDDxWw+Nde8Pzx0E9etju5+HV0sgZ2/6ZsfvXA9fxkCzwtqT+Nr2m+a9NZzZm8mRpc2ol/bvFgqjkRrDobaOzzjLuh4J5OmbR6uiSciJS31wPP0QPjiUloVNJSlAMfntOmzb0yf0nDQatSrvC0bQwFJoLoKAImqGT5zbhwgAdzRdMcwWUElFG4XzI/NF/pJX/1C9kbuVWXQIjoCQ1055CAIAvqQROf5OxmzF/Xgv7ic2qAUXdGHBQ4FDYckWyVFFzskMSsGDtvVKg4pT4vK79l5kUmQpJAhUUkL+13wwcGkV1Yuz0qnS6s2KJS2ck8jc7LwCI7rfjAA7NMmPp89D13GWB2ysMWHaSDEw/Mdb9gWXpbBZ1k7bIF5wBszY+NsrFV8wkZJMYU1s0WQqH02CLMN+3ovV29azaCqyk/P5ONexPdfAZUzbykym0q1/xR5FR7KLUhezy95UZBubg53dNsU/4wSPl/x4au3j1ZbRlFDXmf6jRjAEAIDfwbPurk3kouwAAAAASUVORK5CYII=\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"nx9Kiyyr8Bo1","colab_type":"text"},"source":["Прошу прощения, что не выполни домашнее задание как следует, но абсолютно ен хватает времени на вдумчивое построение и анализ сети."]},{"cell_type":"markdown","metadata":{"id":"kG6oy4el8WXm","colab_type":"text"},"source":["GAN — это генеративно состязательные сети, которые способны создавать изображения используя характерные особенности изображений на которых обучались. Они состоят из 2 нейросетей: генератор — генерирует образцы и дискриминатор — оценивает отличие сгенерированных образцов от образцов тренировачного набора. Проблемами данной нейронной сети является то, что при создании изображений не воспроизводятся мелкие детали и при увеличении размерности данных сеть обучается очень долго и работает не стабильно. \n","\n","Эти проблемы попытались решить создав нейросеть Progressive GAN. Идея ее состоит в то, чтобы обучать сеть сначало на больших объектах и постепенно продвигаться к более мелким. Это позволяет делать процесс обучения более стабильным и улучшает качество изображений.   Кроме того постепенное обучение гораздо легче выполнить, чем обучить сеть за один подход. \n","\n","Так же для улучшения качества изображения авторы сети попытались снизить конкуренцию между генератором и дескриминатором при помощи 2 методов: особой инициализации весов и попиксельная нормировка вектора особенностей изображения. Инициализация весов заключается в следующем. Веса инициализируются с помощью нормального распределения с нулевой средней и единичной дисперсией, и далее во время работы происходит их масштабирование. Идея попиксельной нормализации вектора особенностей заключается в приведении длины характеристического вектора к единице. Нормировка производится в Генераторе после каждого свёрточного слоя."]},{"cell_type":"code","metadata":{"id":"_SSxV7VtOa2k","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}